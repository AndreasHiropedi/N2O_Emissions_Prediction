{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4255afb8-78ea-4e20-9f87-78a2756cea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6cdada-c12d-4f04-8ca6-5cf41f4f8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHAMAU\n",
    "\n",
    "chamau_lag = pd.read_csv(\"../datasets/Chamau_2014-2024_clean_newlag.csv\")\n",
    "chamau_daily = pd.read_csv(\"../datasets/Chamau_Daily_2014-2024_newlag.csv\")\n",
    "\n",
    "chamau_A = chamau_lag[chamau_lag[\"Parcel\"] == \"A\"].copy()\n",
    "chamau_B = chamau_lag[chamau_lag[\"Parcel\"] == \"B\"].copy()\n",
    "\n",
    "chamau_daily_A = chamau_daily[chamau_daily[\"Parcel\"] == \"A\"]\n",
    "chamau_daily_B = chamau_daily[chamau_daily[\"Parcel\"] == \"B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea1aa2e-7b8c-42a7-a3ed-af0644cf9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AESCHI\n",
    "\n",
    "aeschi_lag = pd.read_csv(\"../datasets/Aeschi_2019-20_clean_newlag.csv\")\n",
    "aeschi_daily = pd.read_csv(\"../datasets/Aeschi_Daily_2019-20_newlag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c055ff5-8026-4623-9806-d595d8d85a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OENSINGEN\n",
    "\n",
    "oensingen_lag_1 = pd.read_csv(\"../datasets/Oensingen_2018-19_clean_newlag.csv\")\n",
    "oensingen_daily_1 = pd.read_csv(\"../datasets/Oensingen_Daily_2018-19_clean_newlag.csv\")\n",
    "\n",
    "oensingen_lag_2 = pd.read_csv(\"../datasets/Oensingen_2021-23_clean_newlag.csv\")\n",
    "oensingen_daily_2 = pd.read_csv(\"../datasets/Oensingen_Daily_2021-23_clean_newlag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4227e9a8-6228-444a-b21d-1fe0c3ae75ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TANIKON\n",
    "\n",
    "tanikon_lag = pd.read_csv(\"../datasets/Tanikon_2023-25_clean_newlag.csv\")\n",
    "tanikon_daily = pd.read_csv(\"../datasets/Tanikon_Daily_2023-25_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "892d8949-eb33-4409-816f-80b48c9c0339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOREL\n",
    "\n",
    "forel_lag = pd.read_csv(\"../datasets/Forel_2024-25_clean_newlag.csv\")\n",
    "forel_daily = pd.read_csv(\"../datasets/Forel_Daily_2024-25_clean_newlag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e9539cb-578a-45ac-85e2-5f2b3480dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets = {\n",
    "    \"Chamau\": chamau_lag,\n",
    "    \"Chamau A\": chamau_A,\n",
    "    \"Chamau B\": chamau_B,\n",
    "    \"Aeschi\": aeschi_lag,\n",
    "    \"Oensingen 1\": oensingen_lag_1,\n",
    "    \"Oensingen 2\": oensingen_lag_2,\n",
    "    \"Tanikon\": tanikon_lag,\n",
    "    \"Forel\" : forel_lag\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc2d71ee-f125-4706-b3c7-03fc38a6d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, df in datasets.items():\n",
    "#     print(f\"\\n{name} — {len(df.columns)} columns:\")\n",
    "#     print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc214a74-f6af-4dd4-b8d9-4d7ec2d001bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def train_rf_timeseries_simple(\n",
    "    df, predictors, target, \n",
    "    date_col=\"Date\", test_ratio=0.15,\n",
    "    pca=False, pca_components=0.95,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Fast baseline RandomForest (no hyperparameter search).\n",
    "    Uses Train/Test only (no validation split).\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Keep only available predictors and drop missing ---\n",
    "    available_predictors = [p for p in predictors if p in df.columns]\n",
    "    df = df.dropna(subset=available_predictors + [target]).sort_values(date_col)\n",
    "\n",
    "    # --- Train / Test split (chronological) ---\n",
    "    n = len(df)\n",
    "    n_test = int(n * test_ratio)\n",
    "\n",
    "    train = df.iloc[:n - n_test]\n",
    "    test  = df.iloc[n - n_test:]\n",
    "\n",
    "    X_train = train[available_predictors].to_numpy()\n",
    "    y_train = train[target].to_numpy()\n",
    "    X_test  = test[available_predictors].to_numpy()\n",
    "    y_test  = test[target].to_numpy()\n",
    "\n",
    "    # --- Model ---\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=460,\n",
    "        max_depth=20,\n",
    "        min_samples_split=3,\n",
    "        min_samples_leaf=8,\n",
    "        max_features=0.35,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    steps = []\n",
    "    if pca:\n",
    "        steps.append((\"pca\", PCA(n_components=pca_components)))\n",
    "    steps.append((\"rf\", rf))\n",
    "\n",
    "    model = Pipeline(steps)\n",
    "\n",
    "    # --- Fit on Train only ---\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # --- Predict + Score on Test ---\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r, _ = pearsonr(y_test, y_pred)\n",
    "\n",
    "    # ✅ Ensure dates remain datetime (avoid the 1970 issue)\n",
    "    test_dates = pd.to_datetime(test[date_col])\n",
    "\n",
    "    return {\n",
    "        \"r2\": r2,\n",
    "        \"pearson_r\": r,\n",
    "        \"best_params\": rf.get_params(),\n",
    "        \"n_train\": len(train),\n",
    "        \"n_test\": len(test),\n",
    "        \"pca\": pca,\n",
    "        \"n_components\": (\n",
    "            model.named_steps[\"pca\"].n_components_ if pca else None\n",
    "        ),\n",
    "        \"y_test\": y_test,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"test_dates\": test_dates,\n",
    "        \"model\": model,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc6370de-7b28-4dd0-ae20-795dc6c0d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_structure_families = {\n",
    "    \"lags_only\": [\"_lag\"],\n",
    "    \"roll_mean_only\": [\"roll\", \"mean\"],\n",
    "    \"roll_sum_only\": [\"roll\", \"sum\"],\n",
    "    \"lags_plus_roll\": [\"_lag\", \"roll\"],\n",
    "    \"full_temporal\": [\"_lag\", \"roll\", \"DaysSince_\", \"expHL\"],  \n",
    "    # includes: lags, roll windows, days-since, fertilizer decay\n",
    "}\n",
    "\n",
    "lag_window_options = {\n",
    "    \"1d\": [1],\n",
    "    \"3d\": [3],\n",
    "    \"5d\": [5],\n",
    "    \"7d\": [7],\n",
    "    \"1_3_5\": [1,3,5],\n",
    "    \"1_3_5_7\": [1,3,5,7],\n",
    "    \"3_5_7\": [3,5,7],\n",
    "}\n",
    "\n",
    "decay_modes = {\n",
    "    \"none\": [],\n",
    "    \"HL3\": [\"Fertilizer_N_kg_ha_daily_expHL3d\"],\n",
    "    \"HL7\": [\"Fertilizer_N_kg_ha_daily_expHL7d\"],\n",
    "    \"HL14\": [\"Fertilizer_N_kg_ha_daily_expHL14d\"],\n",
    "    \"all\": [\n",
    "        \"Fertilizer_N_kg_ha_daily_expHL3d\",\n",
    "        \"Fertilizer_N_kg_ha_daily_expHL7d\",\n",
    "        \"Fertilizer_N_kg_ha_daily_expHL14d\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "instantaneous_modes = {\n",
    "    \"instantaneous_only\": \"no_temporal\",\n",
    "    \"instantaneous_plus_temporal\": \"all\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "851f8772-868e-4212-9620-115460a95267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_temporal_predictors(\n",
    "    df, all_predictors,\n",
    "    temporal_families,\n",
    "    lag_days,\n",
    "    decay_vars,\n",
    "    days_since_vars,\n",
    "    include_instantaneous=True\n",
    "):\n",
    "\n",
    "    selected = []\n",
    "\n",
    "    # --- temporal families (lags, rolls, decay) ---\n",
    "    for p in all_predictors:\n",
    "        if any(keyword in p for keyword in temporal_families):\n",
    "            # handle lag windows specifically:\n",
    "            if \"_lag\" in p:\n",
    "                if any(f\"lag{d}\" in p for d in lag_days):\n",
    "                    selected.append(p)\n",
    "            else:\n",
    "                selected.append(p)\n",
    "\n",
    "    # --- fertilizer decay ---\n",
    "    for dvar in decay_vars:\n",
    "        if dvar in df.columns:\n",
    "            selected.append(dvar)\n",
    "\n",
    "    # --- days-since ---\n",
    "    for col in days_since_vars:\n",
    "        if col in df.columns:\n",
    "            selected.append(col)\n",
    "\n",
    "    # --- instantaneous variables ---\n",
    "    if include_instantaneous:\n",
    "        instant = [\n",
    "            c for c in all_predictors\n",
    "            if \"_lag\" not in c\n",
    "            and \"roll\" not in c\n",
    "            and \"DaysSince\" not in c\n",
    "            and \"expHL\" not in c\n",
    "        ]\n",
    "        selected += instant\n",
    "\n",
    "    # --- keep vars that are present in df ---\n",
    "    final = sorted(set([c for c in selected if c in df.columns]))\n",
    "\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8607fc3-f231-4303-a00a-762aeb3e02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_temporal_family(fam_kw):\n",
    "    \"\"\"Return True if the family includes any temporal keywords.\"\"\"\n",
    "    temporal_keys = [\"_lag\", \"roll\", \"DaysSince_\", \"expHL\"]\n",
    "    return any(key in fam_kw for key in temporal_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6623fcc6-2a87-4a8f-ab2c-38d77c045cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total theoretical combinations: 5 × 7 × 5 = 175\n",
      "[1/175] fam=lags_only | lag=1d | decay=none\n"
     ]
    }
   ],
   "source": [
    "# no instatanoues variables\n",
    "\n",
    "# ============================================================\n",
    "#   CUBE SEARCH: families × lag windows × decay modes\n",
    "#   (5 × 7 × 5 = 175 model configurations)\n",
    "# ============================================================\n",
    "\n",
    "df = chamau_lag.copy()\n",
    "dataset_name = \"Chamau\"\n",
    "target = \"N2O_Flux_ln\"\n",
    "\n",
    "# All predictors except obvious non-features\n",
    "all_predictors = [\n",
    "    c for c in df.columns\n",
    "    if c not in [\"Timestamp\", \"Date\", \"N2O_Flux\", \"N2O_Flux_ln\", \"Parcel\"]\n",
    "    and not any(c.endswith(suf) for suf in [\".1\", \".2\", \".3\"])\n",
    "]\n",
    "\n",
    "print(f\"Total theoretical combinations: \"\n",
    "      f\"{len(temporal_structure_families)} × {len(lag_window_options)} × {len(decay_modes)} \"\n",
    "      f\"= {len(temporal_structure_families) * len(lag_window_options) * len(decay_modes)}\")\n",
    "\n",
    "results = []\n",
    "run_idx = 0\n",
    "total_runs = len(temporal_structure_families) * len(lag_window_options) * len(decay_modes)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Helper: Build predictors based on family × lag window × decay\n",
    "# ============================================================\n",
    "\n",
    "def build_predictors(df, all_predictors, fam_keywords, lag_days, decay_vars):\n",
    "    selected = []\n",
    "\n",
    "    # 1) Temporal families (“lags_only”, “roll_mean_only”, etc.)\n",
    "    for col in all_predictors:\n",
    "        # Does this predictor match the temporal family?\n",
    "        if any(kw in col for kw in fam_keywords):\n",
    "\n",
    "            # Special handling: include only the specified lag days\n",
    "            if \"_lag\" in col:\n",
    "                if any(f\"lag{d}\" in col for d in lag_days):\n",
    "                    selected.append(col)\n",
    "            else:\n",
    "                selected.append(col)\n",
    "\n",
    "    # 2) Add decay vars\n",
    "    for dv in decay_vars:\n",
    "        if dv in df.columns:\n",
    "            selected.append(dv)\n",
    "\n",
    "    return sorted(set(selected))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN GRID SEARCH\n",
    "# ============================================================\n",
    "\n",
    "for fam_name, fam_kw in temporal_structure_families.items():\n",
    "    for lag_name, lag_days in lag_window_options.items():\n",
    "        for decay_name, decay_vars in decay_modes.items():\n",
    "\n",
    "            run_idx += 1\n",
    "            print(f\"[{run_idx}/{total_runs}] fam={fam_name} | lag={lag_name} | decay={decay_name}\")\n",
    "\n",
    "            predictors = build_predictors(\n",
    "                df=df,\n",
    "                all_predictors=all_predictors,\n",
    "                fam_keywords=fam_kw,\n",
    "                lag_days=lag_days,\n",
    "                decay_vars=decay_vars\n",
    "            )\n",
    "\n",
    "            # skip weak predictor sets\n",
    "            if len(predictors) < 10:\n",
    "                continue\n",
    "\n",
    "            df_clean = df.dropna(subset=predictors + [target])\n",
    "            if len(df_clean) < 200:\n",
    "                continue\n",
    "\n",
    "            res = train_rf_timeseries_simple(\n",
    "                df_clean, predictors, target,\n",
    "                date_col=\"Timestamp\"\n",
    "            )\n",
    "\n",
    "            results.append({\n",
    "                \"dataset\": dataset_name,\n",
    "                \"struct_family\": fam_name,\n",
    "                \"lag_window\": lag_name,\n",
    "                \"decay\": decay_name,\n",
    "                \"r2\": res[\"r2\"],\n",
    "                \"r\": res[\"pearson_r\"],\n",
    "                \"n_pred\": len(predictors),\n",
    "            })\n",
    "\n",
    "\n",
    "print(\"\\nFinished grid search!\")\n",
    "\n",
    "# ============================================================\n",
    "# RESULTS SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df.sort_values(\"r2\", ascending=False).head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7f974-c305-45c6-8f4a-6bc1864f38b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with instataneous variables\n",
    "\n",
    "# ============================================================\n",
    "#   CUBE SEARCH: families × lag windows × decay modes\n",
    "#   (5 × 7 × 5 = 175 model combinations)\n",
    "# ============================================================\n",
    "\n",
    "df = chamau_lag.copy()\n",
    "dataset_name = \"Chamau\"\n",
    "target = \"N2O_Flux_ln\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Get all usable predictors (exclude non-features)\n",
    "# ------------------------------------------------------------\n",
    "all_predictors = [\n",
    "    c for c in df.columns\n",
    "    if c not in [\"Timestamp\", \"Date\", \"N2O_Flux\", \"N2O_Flux_ln\", \"Parcel\"]\n",
    "    and not any(c.endswith(suf) for suf in [\".1\", \".2\", \".3\"])\n",
    "]\n",
    "\n",
    "# Show total combinations\n",
    "total_runs = (\n",
    "    len(temporal_structure_families)\n",
    "    * len(lag_window_options)\n",
    "    * len(decay_modes)\n",
    ")\n",
    "print(f\"Total theoretical combinations: {total_runs}\")\n",
    "\n",
    "results = []\n",
    "run_idx = 0\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Helper: Build predictors for one model configuration\n",
    "# ============================================================\n",
    "\n",
    "def build_predictors(df, all_predictors, fam_keywords, lag_days, decay_vars):\n",
    "\n",
    "    selected = []\n",
    "\n",
    "    # 1) TEMPORAL FEATURES (controlled by cube search)\n",
    "    for col in all_predictors:\n",
    "\n",
    "        # Check if variable matches temporal keywords for this family\n",
    "        if any(kw in col for kw in fam_keywords):\n",
    "\n",
    "            if \"_lag\" in col:\n",
    "                # Only keep lags for the chosen windows (e.g. lag1, lag3, lag5)\n",
    "                if any(f\"lag{d}\" in col for d in lag_days):\n",
    "                    selected.append(col)\n",
    "\n",
    "            else:\n",
    "                # Rolls, DaysSince_, etc.\n",
    "                selected.append(col)\n",
    "\n",
    "    # 2) FERTILIZER DECAY VARIABLES\n",
    "    for dv in decay_vars:\n",
    "        if dv in df.columns:\n",
    "            selected.append(dv)\n",
    "\n",
    "    # 3) INSTANTANEOUS BASE VARIABLES (ALWAYS INCLUDED)\n",
    "    base_predictors = [\n",
    "        c for c in all_predictors\n",
    "        if \"_lag\" not in c\n",
    "        and \"roll\" not in c\n",
    "        and \"expHL\" not in c\n",
    "    ]\n",
    "    selected += base_predictors\n",
    "\n",
    "    return sorted(set(selected))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN GRID SEARCH LOOP\n",
    "# ============================================================\n",
    "\n",
    "for fam_name, fam_kw in temporal_structure_families.items():\n",
    "    for lag_name, lag_days in lag_window_options.items():\n",
    "        for decay_name, decay_vars in decay_modes.items():\n",
    "\n",
    "            run_idx += 1\n",
    "            print(f\"[{run_idx}/{total_runs}] fam={fam_name} | lag={lag_name} | decay={decay_name}\")\n",
    "\n",
    "            # ---- Build predictor set for this model ----\n",
    "            predictors = build_predictors(\n",
    "                df=df,\n",
    "                all_predictors=all_predictors,\n",
    "                fam_keywords=fam_kw,\n",
    "                lag_days=lag_days,\n",
    "                decay_vars=decay_vars\n",
    "            )\n",
    "\n",
    "            # Skip tiny predictor sets\n",
    "            if len(predictors) < 10:\n",
    "                continue\n",
    "\n",
    "            # Drop NA rows for this model's predictors\n",
    "            df_clean = df.dropna(subset=predictors + [target])\n",
    "            if len(df_clean) < 200:\n",
    "                continue\n",
    "\n",
    "            # ---- Train RF model ----\n",
    "            res = train_rf_timeseries_simple(\n",
    "                df_clean, predictors, target,\n",
    "                date_col=\"Timestamp\"\n",
    "            )\n",
    "\n",
    "            # ---- Store results ----\n",
    "            results.append({\n",
    "                \"dataset\": dataset_name,\n",
    "                \"struct_family\": fam_name,\n",
    "                \"lag_window\": lag_name,\n",
    "                \"decay\": decay_name,\n",
    "                \"r2\": res[\"r2\"],\n",
    "                \"r\": res[\"pearson_r\"],\n",
    "                \"n_pred\": len(predictors),\n",
    "            })\n",
    "\n",
    "print(\"\\nFinished grid search!\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RESULTS SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df.sort_values(\"r2\", ascending=False).head(15))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dsl)",
   "language": "python",
   "name": "dsl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
